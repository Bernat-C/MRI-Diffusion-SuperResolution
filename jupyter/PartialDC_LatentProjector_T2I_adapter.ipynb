{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beb716a8",
   "metadata": {},
   "source": [
    "- Caveats:\n",
    "  - Do the images have phase information or only magnitude bias (two channels). If only one channel we might fall into the magnitude bias (i.e. k-space is collapsed for visualization)\n",
    "  - Condition on k-space mask & measured k-space\n",
    "  - Loss: standard denoising loss (MSE on noise prediction) works well ⚡️ so far we use v_predicion. \n",
    "    - Optionally add perceptual/SSIM auxiliary losses on the final output when supervised paired training is available. However, perceptual losses can encourage hallucination; keep them as regualarizer.\n",
    "  - Data Consistency when sampling from $p(x|y)$. This is known as posterior sampling with a learned prior & project to approximate sampling from the posterior because we alternate stochastic denoising (prior) and deterministic projection (likelihood).\n",
    "    - Train a standard diffusion model on HF images to learn the denoiser $\\epsilon_\\theta$ \n",
    "    - During sampling, incoprterate the measurement constraint by performing data consistency projection at each denoising step: after a denoising step that outputs an image $\\tilde{x}$, replace the low-frequency k-space of $\\tilde{x}$ with the observed k-space from $y$ (or do a gradient step to minimize $\\||A(\\tilde{x}) - y||^2$). This enforces fidelity to measured low frequencies and reduces hallucination. (see [ScoreMD](https://arxiv.org/pdf/2110.05243))\n",
    "  - Overfitting to scanner / protocol: include multi-center/multi-protocol data or use domain-adaptation.\n",
    "  - Mismatch between simulated and real low-freq data: when training with synthetically low-passed images (ideal LPF) but test on different acquisition patterns, performance drops. Use acquisition-matched simulation or train with a diversity of realistic forward operators and noise levels.\n",
    "  - Training on magnitude images: loses phase info — may produce inconsistent k-space and artifacts. Prefer complex-domain training if the downstream requires phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef0e2096",
   "metadata": {},
   "source": [
    "What to do when utilising a novel architecture:\n",
    "- Data domain: train on complex images (two channels: real/imag) or on coil-combined images (e.g., SENSE‐reconstructed). Using complex data preserves phase information and avoids magnitude bias.\n",
    "- Latent Diffusion: Utilise a pretrained VAE in the domain of MRIs rather than a own network.\n",
    "- Network: UNet backbone with time embedding (sinusoidal) and optional cross-attention conditioning on low-res measurement (see SR3 / Cascaded Diffusion literature). Use residual blocks, group normalization, and attention at mid/high resolutions.\n",
    "- Conditioning: provide low-frequency image (zero-filled inverse FFT) as conditional input by channel-concatenation or via cross-attention. Alternatively condition on k-space mask & measured k-space.\n",
    "- Noise schedule: cosine or linear schedule, common defaults from DDPM/EDM. Adjust max noise to match data dynamic range.\n",
    "- Complex handling: either two channels (real/imag) with network learning both, or magnitude + phase decomposition and predict real/imag reconstructions.\n",
    "- Loss: standard denoising loss (MSE on noise prediction) works well. Optionally add perceptual/SSIM auxiliary losses on the final output when supervised paired training is available. Be careful: perceptual losses can encourage hallucination; keep them auxiliary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca8510a",
   "metadata": {},
   "source": [
    "- Initialize sampling with upsampled low-res image rather than pure Gaussian noise. This speeds convergence and reduces hallucination (especially for high upscaling factors).\n",
    "- Data consistency is crucial — models without DC can hallucinate high-frequency content inconsistent with measured low-freq info.\n",
    "- Multi-coil: integrate coil sensitivities explicitly and perform DC in coil k-space; solve for image using CG with the learned prior used as a denoiser (plug-and-play CG).\n",
    "- Patch vs full images: training on patches speeds training; ensure the patch size supports the highest receptive field your UNet needs for contextual structures.\n",
    "- Normalization: normalize per-volume intensity (e.g. whiten or scale by robust max). Keep track of normalization to invert at test time.\n",
    "- Stability: use EMA of weights for sampling; mixed precision training and gradient clipping help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ef6c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import math\n",
    "import random\n",
    "from typing import Union\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "from diffusers.training_utils import EMAModel\n",
    "from diffusers.optimization import get_scheduler\n",
    "from transformers import AutoTokenizer\n",
    "from accelerate.utils import ProjectConfiguration, set_seed\n",
    "from accelerate import Accelerator\n",
    "from diffusers import (\n",
    "    AutoencoderKL,\n",
    "    DDPMScheduler,\n",
    "    UNet2DConditionModel,\n",
    ")\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5076293c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MRIDiffusion.t2iadapter.config import (T2IConfig)\n",
    "from MRIDiffusion.t2iadapter.t2iadapter import (\n",
    "    Adapter_XL,\n",
    ")\n",
    "from MRIDiffusion.t2iadapter.MRIProjector import MRIProjector, LatentMRIProjector, InverseProjectorLearned\n",
    "from MRIDiffusion.t2iadapter.utils import (\n",
    "    import_model_class_from_model_name_or_path,\n",
    "    compute_embeddings_sd1x5,\n",
    "    plot_generated_and_ground_truth,\n",
    "    log_configs,\n",
    "    generate_mri_slices_partial_dc,\n",
    "    print_trainable_parameters,\n",
    "    generate_mri_slices_partial_latent_align_dc,\n",
    ")\n",
    "from MRIDiffusion.slicedMRI import DatasetConfig, PairedMRI_MiniDataset, FastMRILazyDataset\n",
    "from MRIDiffusion.eval import MRIEvaluator\n",
    "from torchmetrics.image import PeakSignalNoiseRatio, StructuralSimilarityIndexMeasure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ca11cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug: bool = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b45c4d",
   "metadata": {},
   "source": [
    "### PairedMRIDataset - Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1324577",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_test_split = (0.8, 0.0, 0.2)\n",
    "assert sum(train_val_test_split) == 1.0, \"Dataset split should sum up to one\"\n",
    "\n",
    "shared_config: dict = {\n",
    "    \"data_dir\": Path(\"./brain_fastMRI_DICOM\"),\n",
    "    \"mode\": \"train\",\n",
    "    \"fractions\": train_val_test_split,\n",
    "    \"target_size\": (512, 512),\n",
    "    \"contrast_filter\": \"T2\",\n",
    "    \"strength_filter\": \"3.0T\",\n",
    "    \"scale_factor\": 4.0,\n",
    "    \"fastMRI_manifest_json\": \"/content/drive/MyDrive/Colab Notebooks/MasterInfo/GenAI/fast_MRI_brain_patient_records_manifest.json\",\n",
    "}\n",
    "config = DatasetConfig(**shared_config)\n",
    "t2i_config = T2IConfig(\n",
    "    train_batch_size=16,\n",
    "    test_batch_size=4,\n",
    "    partial_start_step=350,\n",
    "    max_train_steps=12000,\n",
    "    pretrained_vae_model_name_or_path=\"microsoft/mri-autoencoder-v0.1\",\n",
    ")\n",
    "# train_dataset = PairedMRI_MiniDataset(config=DatasetConfig(**shared_config), verbose=1)\n",
    "train_dataset = FastMRILazyDataset(config=DatasetConfig(**shared_config))\n",
    "shared_config[\"mode\"] = \"test\"\n",
    "test_dataset = FastMRILazyDataset(config=DatasetConfig(**shared_config))\n",
    "# test_dataset = PairedMRI_MiniDataset(config=DatasetConfig(**shared_config), verbose=1)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=t2i_config.train_batch_size, shuffle=True, num_workers=2\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=t2i_config.test_batch_size, shuffle=True, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7ebffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_test_split = [0.8, 0.0, 0.2]\n",
    "assert sum(train_val_test_split) == 1.0, \"Dataset split should sum up to one\"\n",
    "\n",
    "shared_config: dict = {\n",
    "    \"data_dir\": Path(\"./mri_dataset/Data/3T data\"),\n",
    "    \"mode\": \"train\",\n",
    "    \"fractions\": train_val_test_split,\n",
    "    \"slice_axis\": 2,\n",
    "    \"do_registration\": True,\n",
    "    \"do_n4\": False,\n",
    "}\n",
    "config = DatasetConfig(**shared_config)\n",
    "# performs SDEEdit (Stochastic Differential Equation Editing)\n",
    "t2i_config = T2IConfig(train_batch_size=16, test_batch_size=4, partial_start_step=250)\n",
    "train_dataset = PairedMRI_MiniDataset(config=DatasetConfig(**shared_config), verbose=1)\n",
    "shared_config[\"mode\"] = \"test\"\n",
    "test_dataset = PairedMRI_MiniDataset(config=DatasetConfig(**shared_config), verbose=1)\n",
    "train_loader = DataLoader(train_dataset, batch_size=t2i_config.train_batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=t2i_config.test_batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d809fb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "if debug:\n",
    "    def inspect_sample(sample):\n",
    "        hr = sample[\"hr\"]\n",
    "        lr = sample[\"lr\"]\n",
    "        # convert to numpy (handle torch tensors)\n",
    "        if isinstance(hr, torch.Tensor):\n",
    "            hr = hr.detach().cpu().numpy()\n",
    "        if isinstance(lr, torch.Tensor):\n",
    "            lr = lr.detach().cpu().numpy()\n",
    "\n",
    "        print(\"HR shape:\", hr.shape, \"LR shape:\", lr.shape, \" dtype:\", hr.dtype)\n",
    "        print(\n",
    "            \"HR min/max/mean:\",\n",
    "            float(np.nanmin(hr)),\n",
    "            float(np.nanmax(hr)),\n",
    "            float(np.nanmean(hr)),\n",
    "        )\n",
    "        print(\n",
    "            \"LR min/max/mean:\",\n",
    "            float(np.nanmin(lr)),\n",
    "            float(np.nanmax(lr)),\n",
    "            float(np.nanmean(lr)),\n",
    "        )\n",
    "        print(\"HR NaNs:\", int(np.isnan(hr).sum()), \"LR NaNs:\", int(np.isnan(lr).sum()))\n",
    "        print(\"HR unique (sample):\", np.unique(hr.ravel()[:200]).tolist())\n",
    "        # quick histogram (coarse)\n",
    "        hist, edges = np.histogram(hr.ravel(), bins=10)\n",
    "        print(\"HR hist bins:\", hist, \"edges:\", np.round(edges, 4))\n",
    "\n",
    "    num_plots = 40\n",
    "    offset = 0\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=num_plots,\n",
    "        ncols=2,\n",
    "        figsize=(12, num_plots * 6),  # Adjust figure size based on number of plots\n",
    "        dpi=100,\n",
    "    )\n",
    "    if num_plots == 1:\n",
    "        axes = axes[np.newaxis, :]\n",
    "    fig.suptitle(\n",
    "        f\"Generated vs. Ground Truth (First {num_plots} Slices)\", fontsize=16, y=1.02\n",
    "    )\n",
    "    for i in range(num_plots):\n",
    "        data = train_dataset[offset + i]\n",
    "        print(\"=== SAMPLE\", i, \"===\")\n",
    "        inspect_sample(train_dataset[i + offset])\n",
    "        ax_gt = axes[i, 0]\n",
    "        # Ground Truth is typically grayscale (H, W), use 'gray' colormap\n",
    "        # We assume the HR slices have been normalized to [0, 1] or similar\n",
    "        ax_gt.imshow(np.squeeze(data[\"hr\"]))\n",
    "        ax_gt.set_title(f\"HR Slice {i+1}\", fontsize=12)\n",
    "        ax_gt.axis(\"off\")\n",
    "        ax_lr = axes[i, 1]\n",
    "        ax_lr.imshow(np.squeeze(data[\"lr\"]))\n",
    "        ax_lr.set_title(f\"LR Slice {i+1}\", fontsize=12)\n",
    "        ax_lr.axis(\"off\")\n",
    "    plt.tight_layout(rect=[0, 0, 1, 1.01])  # Adjust layout to make space for suptitle\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5937bc4",
   "metadata": {},
   "source": [
    "### Training Setup\n",
    "\n",
    "- SDEEdit (Stochastic Differential Equation Editing): The lr latents are not treated as pure noise but as slightly noisy state (here \\(t=200\\)), then a small amount of noisy is injected (just enough to break the blur and allow the model to inject texture) and finally we denoise it.\n",
    "- Follows the work \"MRI Super-Resolution with Partial Diffusion Models\" by Zhao et al. where they found that the latents of LF and HF MRI scans become indistinguishable after a certain amount of noise\n",
    "- MRIProjector: Use a pseudo-colorization mapping preserving the high dynamic range of MRI while distributing the signal across the R, G, and B channels in a way the VAE can better compress. \n",
    "  - Alternatively, one could train a mapping from the microsoft mri vae to the space of the sd1.5 vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff081168",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging_dir = Path(t2i_config.output_dir, t2i_config.logging_dir)\n",
    "accelerator_project_config = ProjectConfiguration(\n",
    "    project_dir=t2i_config.output_dir, logging_dir=t2i_config.logging_dir\n",
    ")\n",
    "accelerator = Accelerator(\n",
    "    gradient_accumulation_steps=t2i_config.gradient_accumulation_steps,\n",
    "    mixed_precision=t2i_config.mixed_precision,\n",
    "    log_with=t2i_config.report_to,\n",
    "    project_config=accelerator_project_config,\n",
    ")\n",
    "set_seed(t2i_config.seed)\n",
    "os.makedirs(t2i_config.output_dir, exist_ok=True)\n",
    "\n",
    "# load the tokenizers\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    t2i_config.pretrained_model_name_or_path,\n",
    "    subfolder=\"tokenizer\",\n",
    "    revision=t2i_config.revision,\n",
    "    use_fast=False,\n",
    ")\n",
    "# load the correct scheduler and models\n",
    "text_encoder_cls = import_model_class_from_model_name_or_path(\n",
    "    t2i_config.pretrained_model_name_or_path,\n",
    "    t2i_config.revision,\n",
    "    subfolder=\"text_encoder\",\n",
    ")\n",
    "# Load scheduler and models\n",
    "# timesteps defauls to 1000\n",
    "noise_scheduler = DDPMScheduler.from_pretrained(\n",
    "    t2i_config.pretrained_model_name_or_path,\n",
    "    subfolder=\"scheduler\",\n",
    "    prediction_type=t2i_config.ddpm_scheduler_prediction_type,  # velocity prediction\n",
    "    timestep_spacing=t2i_config.ddpm_scheduler_timestep_spacing,  # for zero-SNR\n",
    "    rescale_betas_zero_snr=t2i_config.ddpm_scheduler_rescale_betas_zero_snr,  # enforces pure noise at t=1000\n",
    ")\n",
    "text_encoder = text_encoder_cls.from_pretrained(\n",
    "    t2i_config.pretrained_model_name_or_path,\n",
    "    subfolder=\"text_encoder\",\n",
    "    revision=t2i_config.revision,\n",
    ")\n",
    "vae_path = (\n",
    "    t2i_config.pretrained_model_name_or_path\n",
    "    if t2i_config.pretrained_vae_model_name_or_path is None\n",
    "    else t2i_config.pretrained_vae_model_name_or_path\n",
    ")\n",
    "vae = AutoencoderKL.from_pretrained(\n",
    "    vae_path,  # TODO: play around with this microsoft/mri-autoencoder-v0.1\n",
    "    subfolder=\"vae\" if t2i_config.pretrained_vae_model_name_or_path is None else None,\n",
    "    revision=t2i_config.revision,\n",
    ")\n",
    "unet = UNet2DConditionModel.from_pretrained(\n",
    "    t2i_config.pretrained_model_name_or_path,\n",
    "    subfolder=\"unet\",\n",
    "    revision=t2i_config.revision,\n",
    ")\n",
    "\n",
    "# These are never trained to convert mode collapse (see controlnet paper)\n",
    "vae.requires_grad_(False)\n",
    "text_encoder.requires_grad_(False)\n",
    "unet.requires_grad_(False)\n",
    "\n",
    "print(f\"Using VAE: {vae.config['_name_or_path']}, UNET: {unet.config['_name_or_path']}, Scheduler Steps: {noise_scheduler.config[\"num_train_timesteps\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46343139",
   "metadata": {},
   "outputs": [],
   "source": [
    "if t2i_config.enable_xformers_memory_efficient_attention:\n",
    "    import xformers # pyright: ignore[reportMissingImports]\n",
    "    from packaging import version\n",
    "    xformers_version = version.parse(xformers.__version__)\n",
    "    if xformers_version == version.parse(\"0.0.16\"):\n",
    "        print(\n",
    "            \"xFormers 0.0.16 cannot be used for training in some GPUs. If you observe problems during training, please update xFormers to at least 0.0.17. See https://huggingface.co/docs/diffusers/main/en/optimization/xformers for more details.\"\n",
    "        )\n",
    "    unet.enable_xformers_memory_efficient_attention()\n",
    "if t2i_config.gradient_checkpointing:\n",
    "    unet.enable_gradient_checkpointing()\n",
    "# Enable TF32 for faster training on Ampere GPUs,\n",
    "# cf https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices\n",
    "if t2i_config.allow_tf32:\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "if t2i_config.scale_lr:\n",
    "    learning_rate = (\n",
    "        t2i_config.learning_rate\n",
    "        * t2i_config.gradient_accumulation_steps\n",
    "        * t2i_config.train_batch_size\n",
    "        * accelerator.num_processes\n",
    "    )\n",
    "else:\n",
    "    learning_rate = t2i_config.learning_rate\n",
    "# Use 8-bit Adam for lower memory usage or to fine-tune the model in 16GB GPUs\n",
    "if t2i_config.use_8bit_adam:\n",
    "    try:\n",
    "        import bitsandbytes as bnb # pyright: ignore[reportMissingImports]\n",
    "    except ImportError:\n",
    "        raise ImportError(\n",
    "            \"To use 8-bit Adam, please install the bitsandbytes library: `pip install bitsandbytes`.\"\n",
    "        )\n",
    "    optimizer_class = bnb.optim.AdamW8bit\n",
    "else:\n",
    "    optimizer_class = torch.optim.AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a13c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter = Adapter_XL(\n",
    "    channels=[320, 640, 1280, 1280],\n",
    "    nums_rb=3,\n",
    "    cin=3 * 64,\n",
    "    ksize=3,\n",
    "    sk=True,\n",
    "    use_conv=True,\n",
    ").to(accelerator.device)\n",
    "is_special_vae = (\n",
    "    t2i_config.pretrained_vae_model_name_or_path == \"microsoft/mri-autoencoder-v0.1\"\n",
    ")\n",
    "output_dims = 2 if is_special_vae else 3\n",
    "latent_projector = LatentMRIProjector(\n",
    "    spatial_in=128, spatial_out=64, in_channels=4, out_channels=4\n",
    ").to(accelerator.device)\n",
    "mri_projector = MRIProjector(output_dims=2).to(accelerator.device)\n",
    "inverse_latent_projector = InverseProjectorLearned(spatial_in=64, spatial_out=128).to(\n",
    "    accelerator.device\n",
    ")\n",
    "params_to_optimize = (\n",
    "    list(adapter.parameters())\n",
    "    + list(latent_projector.parameters())\n",
    "    + list(mri_projector.parameters())\n",
    "    + list(inverse_latent_projector.parameters())\n",
    ")\n",
    "optimizer = optimizer_class(\n",
    "    params_to_optimize,\n",
    "    lr=learning_rate,\n",
    "    betas=(t2i_config.adam_beta1, t2i_config.adam_beta2),\n",
    "    weight_decay=t2i_config.adam_weight_decay,\n",
    "    eps=t2i_config.adam_epsilon,\n",
    ")\n",
    "\n",
    "# For mixed precision training we cast the text_encoder and vae weights to half-precision\n",
    "# as these models are only used for inference, keeping weights in full precision is not required.\n",
    "weight_dtype = torch.float32\n",
    "if accelerator.mixed_precision == \"fp16\":\n",
    "    weight_dtype = torch.float16\n",
    "elif accelerator.mixed_precision == \"bf16\":\n",
    "    weight_dtype = torch.bfloat16\n",
    "# Move vae, unet and text_encoder to device and cast to weight_dtype\n",
    "# The VAE is in float32 to avoid NaN losses.\n",
    "if t2i_config.pretrained_vae_model_name_or_path is not None:\n",
    "    vae.to(accelerator.device, dtype=weight_dtype)\n",
    "else:\n",
    "    vae.to(accelerator.device, dtype=torch.float32)\n",
    "unet.to(accelerator.device)\n",
    "text_encoder.to(accelerator.device, dtype=weight_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e444f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first compute all the embeddings so that we can free up the text encoders from memory.\n",
    "text_encoders = [text_encoder]\n",
    "tokenizers = [tokenizer]\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "# Scheduler and math around the number of training steps.\n",
    "overrode_max_train_steps = False\n",
    "# num_update_steps_per_epoch = math.ceil(len(train_dataloader) / args.gradient_accumulation_steps)\n",
    "num_update_steps_per_epoch = math.ceil(1e7 / t2i_config.gradient_accumulation_steps)\n",
    "if t2i_config.max_train_steps is None:\n",
    "    t2i_config.max_train_steps = (\n",
    "        t2i_config.num_train_epochs * num_update_steps_per_epoch\n",
    "    )\n",
    "    overrode_max_train_steps = True\n",
    "lr_scheduler = get_scheduler(\n",
    "    t2i_config.lr_scheduler_name,\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=t2i_config.lr_warmup_steps * accelerator.num_processes,\n",
    "    num_training_steps=t2i_config.max_train_steps * accelerator.num_processes,\n",
    "    num_cycles=t2i_config.lr_num_cycles,\n",
    "    power=t2i_config.lr_power,\n",
    ")\n",
    "ema_adapter = EMAModel(\n",
    "    adapter.parameters(),\n",
    "    model_cls=adapter.__class__,  # Custom class, passing it here helps with some utilities\n",
    "    decay=0.9999,\n",
    ")\n",
    "# Prepare everything with our `accelerator`.\n",
    "adapter, latent_projector, mri_projector, inverse_latent_projector, unet, optimizer, train_dataloader, lr_scheduler = accelerator.prepare(\n",
    "    adapter, latent_projector, mri_projector, inverse_latent_projector, unet, optimizer, train_loader, lr_scheduler\n",
    ")\n",
    "\n",
    "if accelerator.is_main_process:\n",
    "    tracker_config = dict(vars(t2i_config))\n",
    "    # accelerator.init_trackers(args.tracker_project_name, config=tracker_config)\n",
    "\n",
    "total_batch_size = (\n",
    "    t2i_config.train_batch_size\n",
    "    * accelerator.num_processes\n",
    "    * t2i_config.gradient_accumulation_steps\n",
    ")\n",
    "\n",
    "print(f\"Using VAE: {vae.config['_name_or_path']}, UNET: {unet.config['_name_or_path']}, Scheduler Steps: {noise_scheduler.config[\"num_train_timesteps\"]}\")\n",
    "print_trainable_parameters(latent_projector, name=\"MRI Latent Projector\")\n",
    "print_trainable_parameters(adapter, name=\"T2I-Adapter\")\n",
    "print_trainable_parameters(mri_projector, name=\"MRI-Projector\")\n",
    "print_trainable_parameters(inverse_latent_projector, name=\"Inverse MRI Latent Projector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f251115",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df40fa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd64c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(\n",
    "    entity=\"hannes-leonhard\",\n",
    "    project=\"mir-sr\",\n",
    "    config=log_configs(t2i_config=t2i_config, dataset_config=config),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392b9883",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = 0\n",
    "first_epoch = 0\n",
    "initial_global_step = 0\n",
    "loss_history = []\n",
    "random.seed(t2i_config.seed)\n",
    "vis_idx = random.randrange(0, len(test_dataset))\n",
    "print(f\"Using test entry {vis_idx} for training visualization\")\n",
    "psnr = PeakSignalNoiseRatio(data_range=1.0).to(accelerator.device)\n",
    "ssim = StructuralSimilarityIndexMeasure(data_range=1.0).to(accelerator.device)\n",
    "\n",
    "random.seed(t2i_config.seed)\n",
    "progress_bar = tqdm(\n",
    "    range(0, t2i_config.max_train_steps),\n",
    "    initial=initial_global_step,\n",
    "    desc=\"Steps\",\n",
    "    disable=not accelerator.is_local_main_process,\n",
    ")\n",
    "prompt_embeds: Union[torch.Tensor, None] = None\n",
    "\n",
    "for epoch in range(first_epoch, t2i_config.num_train_epochs):\n",
    "    adapter.train()\n",
    "    latent_projector.train()\n",
    "    mri_projector.train()\n",
    "    inverse_latent_projector.train()\n",
    "    for step, batch in enumerate(train_loader):\n",
    "        with accelerator.accumulate(adapter):\n",
    "            bsz = batch[\"hr\"].shape[0]\n",
    "            # Use projector for HR (Target) and LR (Condition)\n",
    "            hr_rgb = mri_projector(batch[\"hr\"].to(accelerator.device).float())\n",
    "            condition = mri_projector(batch[\"lr\"].to(accelerator.device).float())\n",
    "\n",
    "            latents = vae.encode(hr_rgb.to(vae.dtype)).latent_dist.sample()\n",
    "            latents = latents * vae.config.scaling_factor\n",
    "            latents = latents.to(weight_dtype)\n",
    "            # project mri latents to rgb latente\n",
    "            latents_projected = latent_projector(latents)\n",
    "            # calculate inverse latent loss\n",
    "            latent_projected_aug = latents_projected + 0.01 * torch.randn_like(\n",
    "                latents_projected\n",
    "            )\n",
    "            latents_inverse = inverse_latent_projector(latent_projected_aug)\n",
    "            latents_loss = t2i_config.lambda_latent * F.mse_loss(\n",
    "                latents_inverse, latents\n",
    "            )\n",
    "            latent_image_loss = t2i_config.lambda_latent_image * F.l1_loss(\n",
    "                vae.decode(latents_inverse / vae.config.scaling_factor), hr_rgb\n",
    "            )\n",
    "            # Noise generation\n",
    "            noise = torch.randn_like(latents_projected)\n",
    "            bsz = latents_projected.shape[0]\n",
    "\n",
    "            # SDEEdit\n",
    "            timesteps = torch.randint(\n",
    "                0,\n",
    "                t2i_config.partial_start_step,\n",
    "                (bsz,),\n",
    "                device=latents_projected.device,\n",
    "            ).long()\n",
    "            noisy_latents = noise_scheduler.add_noise(\n",
    "                latents_projected, noise, timesteps\n",
    "            )\n",
    "            if prompt_embeds is None:\n",
    "                prompt_embeds = compute_embeddings_sd1x5(\n",
    "                    batch=batch,\n",
    "                    proportion_empty_prompts=0.1,\n",
    "                    text_encoders=text_encoders,\n",
    "                    tokenizers=tokenizers,\n",
    "                    accelerator=accelerator,\n",
    "                )[\"prompt_embeds\"]\n",
    "            # Adapter conditioning\n",
    "            down_block_additional_residuals = adapter(condition)\n",
    "            model_pred = unet(\n",
    "                noisy_latents,\n",
    "                timesteps,\n",
    "                encoder_hidden_states=prompt_embeds,\n",
    "                down_block_additional_residuals=down_block_additional_residuals,\n",
    "            ).sample\n",
    "\n",
    "            # Loss Computation\n",
    "            if noise_scheduler.config.prediction_type == \"epsilon\":\n",
    "                target = noise\n",
    "            elif noise_scheduler.config.prediction_type == \"v_prediction\":\n",
    "                target = noise_scheduler.get_velocity(\n",
    "                    latents_projected, noise, timesteps\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(\n",
    "                    f\"Unknown prediction type {noise_scheduler.config.prediction_type}\"\n",
    "                )\n",
    "\n",
    "            loss = F.mse_loss(model_pred.float(), target.float(), reduction=\"mean\")\n",
    "            total_loss = loss + latents_loss + latent_image_loss\n",
    "            loss_history.append(loss.detach().item())\n",
    "            accelerator.backward(total_loss)\n",
    "\n",
    "            if accelerator.sync_gradients:\n",
    "                params_to_clip = (\n",
    "                    list(adapter.parameters())\n",
    "                    + list(inverse_latent_projector.parameters())\n",
    "                    + list(mri_projector.parameters())\n",
    "                )\n",
    "                accelerator.clip_grad_norm_(params_to_clip, t2i_config.max_grad_norm)\n",
    "                optimizer.step()\n",
    "                lr_scheduler.step()\n",
    "                if accelerator.is_main_process:\n",
    "                    unwrapped_adapter = accelerator.unwrap_model(adapter)\n",
    "                    ema_adapter.step(unwrapped_adapter.parameters())\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        if accelerator.sync_gradients:\n",
    "            progress_bar.update(1)\n",
    "            global_step += 1\n",
    "\n",
    "            # --- Validation / Visualization ---\n",
    "            if accelerator.is_main_process:\n",
    "                if global_step % t2i_config.media_reporting_step == 0:\n",
    "                    item = test_dataset[vis_idx]\n",
    "                    # Add batch dimension\n",
    "                    item[\"hr\"] = item[\"hr\"].unsqueeze(0)\n",
    "                    item[\"lr\"] = item[\"lr\"].unsqueeze(0)\n",
    "                    item[\"txt\"] = [item[\"txt\"]]\n",
    "\n",
    "                    with torch.no_grad():\n",
    "                        prompt_embeds_eval = compute_embeddings_sd1x5(\n",
    "                            batch=item,\n",
    "                            proportion_empty_prompts=0.0,\n",
    "                            text_encoders=text_encoders,\n",
    "                            tokenizers=tokenizers,\n",
    "                            accelerator=accelerator,\n",
    "                            is_train=False,\n",
    "                        )[\"prompt_embeds\"]\n",
    "                    images, _ = generate_mri_slices_partial_latent_align_dc(\n",
    "                        batch=item,\n",
    "                        adapter=adapter,\n",
    "                        mri_projector=mri_projector,\n",
    "                        latent_projector=latent_projector,\n",
    "                        inverse_latent_projector=inverse_latent_projector,\n",
    "                        unet=unet,\n",
    "                        vae=vae,\n",
    "                        noise_scheduler=noise_scheduler,\n",
    "                        prompt_embeds=prompt_embeds_eval,\n",
    "                        start_step=t2i_config.partial_start_step,  # Start from t=250\n",
    "                        num_inference_steps=500,  # Scheduler will slice this\n",
    "                        weight_dtype=weight_dtype,\n",
    "                        accelerator=accelerator,\n",
    "                        use_data_consistency=True,\n",
    "                        dc_reduction_factor=1.7,\n",
    "                        taper=0.12,\n",
    "                        apply_final_pixel_dc=False,\n",
    "                    )\n",
    "\n",
    "                    adapter.train()\n",
    "                    mri_projector.train()\n",
    "                    latent_projector.train()\n",
    "                    inverse_latent_projector.train()\n",
    "                    views = []\n",
    "                    images_gt = wandb.Image(\n",
    "                        item[\"hr\"].numpy().transpose((1, 2, 0)),\n",
    "                        caption=\"GT MRI\",\n",
    "                    )\n",
    "                    images_lr = wandb.Image(\n",
    "                        item[\"lr\"].numpy().transpose((1, 2, 0)),\n",
    "                        caption=\"Low-Res MRI\",\n",
    "                    )\n",
    "                    views.append(images_gt)\n",
    "                    views.append(images_lr)\n",
    "                    channels = images.shape[3]\n",
    "                    for dim in range(channels):\n",
    "                        images_gen = wandb.Image(\n",
    "                            images[0, :, :, dim][:, :, np.newaxis],\n",
    "                            caption=f\"Gen MRI (axis {dim}) - Partial Diff\",\n",
    "                        )\n",
    "                        views.append(images_gen)\n",
    "                    run.log({\"validation views\": views})\n",
    "\n",
    "                    # Metrics calculation\n",
    "                    if item[\"hr\"].ndim == 3:\n",
    "                        gt = item[\"hr\"].unsqueeze(1).expand(1, channels, 512, 512)\n",
    "                    else:\n",
    "                        gt = item[\"hr\"].expand(1, channels, 512, 512)\n",
    "\n",
    "                    metrics_val = MRIEvaluator.eval_all_metrics(\n",
    "                        ground_truth=gt.to(accelerator.device),\n",
    "                        generated=torch.from_numpy(images)\n",
    "                        .permute(0, 3, 1, 2)\n",
    "                        .to(accelerator.device),\n",
    "                        psnr=psnr,\n",
    "                        ssim=ssim,\n",
    "                    )\n",
    "                    run.log(\n",
    "                        {\n",
    "                            \"val_hfen\": metrics_val[0],\n",
    "                            \"val_nmse\": metrics_val[1],\n",
    "                            \"val_psnr\": metrics_val[2],\n",
    "                            \"val_ssim\": metrics_val[3],\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                if global_step % t2i_config.checkpointing_steps == 0:\n",
    "                    save_path = os.path.join(\n",
    "                        t2i_config.output_dir, f\"checkpoint-{global_step}\"\n",
    "                    )\n",
    "                    os.makedirs(save_path, exist_ok=True)\n",
    "                    unwrapped_adapter = accelerator.unwrap_model(adapter)\n",
    "                    ema_adapter.store(unwrapped_adapter.parameters())\n",
    "                    ema_adapter.copy_to(unwrapped_adapter.parameters())\n",
    "                    torch.save(\n",
    "                        unwrapped_adapter.state_dict(),\n",
    "                        os.path.join(save_path, \"adapter.pt\"),\n",
    "                    )\n",
    "                    ema_adapter.restore(unwrapped_adapter.parameters())\n",
    "                    print(f\"Saved EMA checkpoint to {save_path}\")\n",
    "\n",
    "        logs = {\n",
    "            \"loss\": total_loss.detach().item(),\n",
    "            \"diffusion_loss\": loss.detach().item(),\n",
    "            \"latent_loss\": latents_loss.detach().item(),\n",
    "            \"latent_image_loss\": latent_image_loss.detach().item(),\n",
    "            \"lr\": lr_scheduler.get_last_lr()[0],\n",
    "            \"epoch\": epoch,\n",
    "        }\n",
    "        run.log(logs)\n",
    "        progress_bar.set_postfix(**logs)\n",
    "\n",
    "# After training is done\n",
    "if accelerator.is_main_process:\n",
    "    unwrapped_adapter = accelerator.unwrap_model(adapter)\n",
    "    # Final EMA Save\n",
    "    ema_adapter.copy_to(unwrapped_adapter.parameters())\n",
    "    torch.save(\n",
    "        unwrapped_adapter.state_dict(),\n",
    "        os.path.join(t2i_config.output_dir, \"adapter_tuned.pt\"),\n",
    "    )\n",
    "    torch.save(\n",
    "        mri_projector.state_dict(),\n",
    "        os.path.join(t2i_config.output_dir, \"mri_projector.pt\"),\n",
    "    )\n",
    "    torch.save(\n",
    "        inverse_latent_projector.state_dict(),\n",
    "        os.path.join(t2i_config.output_dir, \"inverse_latent_projector.pt\"),\n",
    "    )\n",
    "    print(\"Training finished. Saved final T2I-Adapter EMA.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755ed8df",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "- Run over the whoole validation dataset and aggreate PSNR; SSIM; HFEN and NMSE\n",
    "- Plot testing views\n",
    "- Logs aggreagted metrics to wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dff7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <function _draw_all_if_interactive at 0x11692a090> (for post_execute), with arguments args (),kwargs {}:\n"
     ]
    },
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRecursionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/pyplot.py:279\u001b[39m, in \u001b[36m_draw_all_if_interactive\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_draw_all_if_interactive\u001b[39m() -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m matplotlib.is_interactive():\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m         \u001b[43mdraw_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/_pylab_helpers.py:131\u001b[39m, in \u001b[36mGcf.draw_all\u001b[39m\u001b[34m(cls, force)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m manager \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.get_all_fig_managers():\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m force \u001b[38;5;129;01mor\u001b[39;00m manager.canvas.figure.stale:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m         \u001b[43mmanager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcanvas\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/backend_bases.py:1891\u001b[39m, in \u001b[36mFigureCanvasBase.draw_idle\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1889\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_idle_drawing:\n\u001b[32m   1890\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._idle_draw_cntx():\n\u001b[32m-> \u001b[39m\u001b[32m1891\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/backends/backend_agg.py:382\u001b[39m, in \u001b[36mFigureCanvasAgg.draw\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[32m    380\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.toolbar._wait_cursor_for_draw_cm() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.toolbar\n\u001b[32m    381\u001b[39m       \u001b[38;5;28;01melse\u001b[39;00m nullcontext()):\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfigure\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    383\u001b[39m     \u001b[38;5;66;03m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[32m    384\u001b[39m     \u001b[38;5;66;03m# don't forget to call the superclass.\u001b[39;00m\n\u001b[32m    385\u001b[39m     \u001b[38;5;28msuper\u001b[39m().draw()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/artist.py:94\u001b[39m, in \u001b[36m_finalize_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer, *args, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdraw_wrapper\u001b[39m(artist, renderer, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     result = \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m renderer._rasterizing:\n\u001b[32m     96\u001b[39m         renderer.stop_rasterizing()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/artist.py:71\u001b[39m, in \u001b[36mallow_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     69\u001b[39m         renderer.start_filter()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/figure.py:3257\u001b[39m, in \u001b[36mFigure.draw\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m   3254\u001b[39m             \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[32m   3256\u001b[39m     \u001b[38;5;28mself\u001b[39m.patch.draw(renderer)\n\u001b[32m-> \u001b[39m\u001b[32m3257\u001b[39m     \u001b[43mmimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3260\u001b[39m     renderer.close_group(\u001b[33m'\u001b[39m\u001b[33mfigure\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   3261\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/image.py:134\u001b[39m, in \u001b[36m_draw_list_compositing_images\u001b[39m\u001b[34m(renderer, parent, artists, suppress_composite)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m         \u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[32m    137\u001b[39m     image_group = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/artist.py:71\u001b[39m, in \u001b[36mallow_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     69\u001b[39m         renderer.start_filter()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/axes/_base.py:3181\u001b[39m, in \u001b[36m_AxesBase.draw\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m   3178\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m artists_rasterized:\n\u001b[32m   3179\u001b[39m     _draw_rasterized(\u001b[38;5;28mself\u001b[39m.get_figure(root=\u001b[38;5;28;01mTrue\u001b[39;00m), artists_rasterized, renderer)\n\u001b[32m-> \u001b[39m\u001b[32m3181\u001b[39m \u001b[43mmimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3182\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3184\u001b[39m renderer.close_group(\u001b[33m'\u001b[39m\u001b[33maxes\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   3185\u001b[39m \u001b[38;5;28mself\u001b[39m.stale = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/image.py:134\u001b[39m, in \u001b[36m_draw_list_compositing_images\u001b[39m\u001b[34m(renderer, parent, artists, suppress_composite)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m         \u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[32m    137\u001b[39m     image_group = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/artist.py:71\u001b[39m, in \u001b[36mallow_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     69\u001b[39m         renderer.start_filter()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/axis.py:1415\u001b[39m, in \u001b[36mAxis.draw\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m   1412\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1413\u001b[39m renderer.open_group(\u001b[34m__name__\u001b[39m, gid=\u001b[38;5;28mself\u001b[39m.get_gid())\n\u001b[32m-> \u001b[39m\u001b[32m1415\u001b[39m ticks_to_draw = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_ticks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1416\u001b[39m tlb1, tlb2 = \u001b[38;5;28mself\u001b[39m._get_ticklabel_bboxes(ticks_to_draw, renderer)\n\u001b[32m   1418\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks_to_draw:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/axis.py:1294\u001b[39m, in \u001b[36mAxis._update_ticks\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1292\u001b[39m major_locs = \u001b[38;5;28mself\u001b[39m.get_majorticklocs()\n\u001b[32m   1293\u001b[39m major_labels = \u001b[38;5;28mself\u001b[39m.major.formatter.format_ticks(major_locs)\n\u001b[32m-> \u001b[39m\u001b[32m1294\u001b[39m major_ticks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_major_ticks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmajor_locs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1295\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tick, loc, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(major_ticks, major_locs, major_labels):\n\u001b[32m   1296\u001b[39m     tick.update_position(loc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/axis.py:1677\u001b[39m, in \u001b[36mAxis.get_major_ticks\u001b[39m\u001b[34m(self, numticks)\u001b[39m\n\u001b[32m   1675\u001b[39m     tick = \u001b[38;5;28mself\u001b[39m._get_tick(major=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1676\u001b[39m     \u001b[38;5;28mself\u001b[39m.majorTicks.append(tick)\n\u001b[32m-> \u001b[39m\u001b[32m1677\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_copy_tick_props\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmajorTicks\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtick\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1679\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.majorTicks[:numticks]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/axis.py:1623\u001b[39m, in \u001b[36mAxis._copy_tick_props\u001b[39m\u001b[34m(self, src, dest)\u001b[39m\n\u001b[32m   1621\u001b[39m dest.label1.update_from(src.label1)\n\u001b[32m   1622\u001b[39m dest.label2.update_from(src.label2)\n\u001b[32m-> \u001b[39m\u001b[32m1623\u001b[39m \u001b[43mdest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick1line\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick1line\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1624\u001b[39m dest.tick2line.update_from(src.tick2line)\n\u001b[32m   1625\u001b[39m dest.gridline.update_from(src.gridline)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/lines.py:1358\u001b[39m, in \u001b[36mLine2D.update_from\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m   1355\u001b[39m \u001b[38;5;28mself\u001b[39m._solidjoinstyle = other._solidjoinstyle\n\u001b[32m   1357\u001b[39m \u001b[38;5;28mself\u001b[39m._linestyle = other._linestyle\n\u001b[32m-> \u001b[39m\u001b[32m1358\u001b[39m \u001b[38;5;28mself\u001b[39m._marker = \u001b[43mMarkerStyle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarker\u001b[49m\u001b[43m=\u001b[49m\u001b[43mother\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_marker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1359\u001b[39m \u001b[38;5;28mself\u001b[39m._drawstyle = other._drawstyle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/markers.py:248\u001b[39m, in \u001b[36mMarkerStyle.__init__\u001b[39m\u001b[34m(self, marker, fillstyle, transform, capstyle, joinstyle)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;28mself\u001b[39m._user_joinstyle = JoinStyle(joinstyle) \u001b[38;5;28;01mif\u001b[39;00m joinstyle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[38;5;28mself\u001b[39m._set_fillstyle(fillstyle)\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_marker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarker\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/markers.py:323\u001b[39m, in \u001b[36mMarkerStyle._set_marker\u001b[39m\u001b[34m(self, marker)\u001b[39m\n\u001b[32m    321\u001b[39m     \u001b[38;5;28mself\u001b[39m._marker_function = \u001b[38;5;28mself\u001b[39m._set_tuple_marker\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(marker, MarkerStyle):\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m     \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m = \u001b[43mcopy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarker\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__dict__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/copy.py:131\u001b[39m, in \u001b[36mdeepcopy\u001b[39m\u001b[34m(x, memo, _nil)\u001b[39m\n\u001b[32m    129\u001b[39m copier = _deepcopy_dispatch.get(\u001b[38;5;28mcls\u001b[39m)\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     y = \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/copy.py:202\u001b[39m, in \u001b[36m_deepcopy_dict\u001b[39m\u001b[34m(x, memo, deepcopy)\u001b[39m\n\u001b[32m    200\u001b[39m memo[\u001b[38;5;28mid\u001b[39m(x)] = y\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x.items():\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     y[deepcopy(key, memo)] = \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/copy.py:138\u001b[39m, in \u001b[36mdeepcopy\u001b[39m\u001b[34m(x, memo, _nil)\u001b[39m\n\u001b[32m    136\u001b[39m copier = \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33m__deepcopy__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     y = \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    140\u001b[39m     reductor = dispatch_table.get(\u001b[38;5;28mcls\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/path.py:285\u001b[39m, in \u001b[36mPath.__deepcopy__\u001b[39m\u001b[34m(self, memo)\u001b[39m\n\u001b[32m    280\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    281\u001b[39m \u001b[33;03mReturn a deepcopy of the `Path`.  The `Path` will not be\u001b[39;00m\n\u001b[32m    282\u001b[39m \u001b[33;03mreadonly, even if the source `Path` is.\u001b[39;00m\n\u001b[32m    283\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    284\u001b[39m \u001b[38;5;66;03m# Deepcopying arrays (vertices, codes) strips the writeable=False flag.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m p = \u001b[43mcopy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    286\u001b[39m p._readonly = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/copy.py:157\u001b[39m, in \u001b[36mdeepcopy\u001b[39m\u001b[34m(x, memo, _nil)\u001b[39m\n\u001b[32m    155\u001b[39m                 y = x\n\u001b[32m    156\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m                 y = \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/copy.py:234\u001b[39m, in \u001b[36m_reconstruct\u001b[39m\u001b[34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m args:\n\u001b[32m    233\u001b[39m     args = (deepcopy(arg, memo) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m y = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[32m    236\u001b[39m     memo[\u001b[38;5;28mid\u001b[39m(x)] = y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/copy.py:233\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    231\u001b[39m deep = memo \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m args:\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m     args = (\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n\u001b[32m    234\u001b[39m y = func(*args)\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/copy.py:138\u001b[39m, in \u001b[36mdeepcopy\u001b[39m\u001b[34m(x, memo, _nil)\u001b[39m\n\u001b[32m    136\u001b[39m copier = \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33m__deepcopy__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     y = \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    140\u001b[39m     reductor = dispatch_table.get(\u001b[38;5;28mcls\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/path.py:285\u001b[39m, in \u001b[36mPath.__deepcopy__\u001b[39m\u001b[34m(self, memo)\u001b[39m\n\u001b[32m    280\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    281\u001b[39m \u001b[33;03mReturn a deepcopy of the `Path`.  The `Path` will not be\u001b[39;00m\n\u001b[32m    282\u001b[39m \u001b[33;03mreadonly, even if the source `Path` is.\u001b[39;00m\n\u001b[32m    283\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    284\u001b[39m \u001b[38;5;66;03m# Deepcopying arrays (vertices, codes) strips the writeable=False flag.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m p = \u001b[43mcopy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    286\u001b[39m p._readonly = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/copy.py:157\u001b[39m, in \u001b[36mdeepcopy\u001b[39m\u001b[34m(x, memo, _nil)\u001b[39m\n\u001b[32m    155\u001b[39m                 y = x\n\u001b[32m    156\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m                 y = \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/copy.py:234\u001b[39m, in \u001b[36m_reconstruct\u001b[39m\u001b[34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m args:\n\u001b[32m    233\u001b[39m     args = (deepcopy(arg, memo) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m y = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[32m    236\u001b[39m     memo[\u001b[38;5;28mid\u001b[39m(x)] = y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/copy.py:233\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    231\u001b[39m deep = memo \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m args:\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m     args = (\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n\u001b[32m    234\u001b[39m y = func(*args)\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep:\n",
      "    \u001b[31m[... skipping similar frames: Path.__deepcopy__ at line 285 (590 times), deepcopy at line 138 (590 times), <genexpr> at line 233 (589 times), _reconstruct at line 234 (589 times), deepcopy at line 157 (589 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/copy.py:157\u001b[39m, in \u001b[36mdeepcopy\u001b[39m\u001b[34m(x, memo, _nil)\u001b[39m\n\u001b[32m    155\u001b[39m                 y = x\n\u001b[32m    156\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m                 y = \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/copy.py:234\u001b[39m, in \u001b[36m_reconstruct\u001b[39m\u001b[34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m args:\n\u001b[32m    233\u001b[39m     args = (deepcopy(arg, memo) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m y = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[32m    236\u001b[39m     memo[\u001b[38;5;28mid\u001b[39m(x)] = y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/copy.py:233\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    231\u001b[39m deep = memo \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m args:\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m     args = (\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n\u001b[32m    234\u001b[39m y = func(*args)\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/copy.py:138\u001b[39m, in \u001b[36mdeepcopy\u001b[39m\u001b[34m(x, memo, _nil)\u001b[39m\n\u001b[32m    136\u001b[39m copier = \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33m__deepcopy__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     y = \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    140\u001b[39m     reductor = dispatch_table.get(\u001b[38;5;28mcls\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/path.py:285\u001b[39m, in \u001b[36mPath.__deepcopy__\u001b[39m\u001b[34m(self, memo)\u001b[39m\n\u001b[32m    280\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    281\u001b[39m \u001b[33;03mReturn a deepcopy of the `Path`.  The `Path` will not be\u001b[39;00m\n\u001b[32m    282\u001b[39m \u001b[33;03mreadonly, even if the source `Path` is.\u001b[39;00m\n\u001b[32m    283\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    284\u001b[39m \u001b[38;5;66;03m# Deepcopying arrays (vertices, codes) strips the writeable=False flag.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m p = \u001b[43mcopy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    286\u001b[39m p._readonly = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "\u001b[31mRecursionError\u001b[39m: maximum recursion depth exceeded"
     ]
    },
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRecursionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/IPython/core/formatters.py:402\u001b[39m, in \u001b[36mBaseFormatter.__call__\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[32m    404\u001b[39m method = get_real_method(obj, \u001b[38;5;28mself\u001b[39m.print_method)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/IPython/core/pylabtools.py:170\u001b[39m, in \u001b[36mprint_figure\u001b[39m\u001b[34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[39m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend_bases\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[32m    168\u001b[39m     FigureCanvasBase(fig)\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m \u001b[43mfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcanvas\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytes_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m data = bytes_io.getvalue()\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fmt == \u001b[33m'\u001b[39m\u001b[33msvg\u001b[39m\u001b[33m'\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/backend_bases.py:2155\u001b[39m, in \u001b[36mFigureCanvasBase.print_figure\u001b[39m\u001b[34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[39m\n\u001b[32m   2152\u001b[39m     \u001b[38;5;66;03m# we do this instead of `self.figure.draw_without_rendering`\u001b[39;00m\n\u001b[32m   2153\u001b[39m     \u001b[38;5;66;03m# so that we can inject the orientation\u001b[39;00m\n\u001b[32m   2154\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(renderer, \u001b[33m\"\u001b[39m\u001b[33m_draw_disabled\u001b[39m\u001b[33m\"\u001b[39m, nullcontext)():\n\u001b[32m-> \u001b[39m\u001b[32m2155\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfigure\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2156\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m bbox_inches:\n\u001b[32m   2157\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches == \u001b[33m\"\u001b[39m\u001b[33mtight\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/artist.py:94\u001b[39m, in \u001b[36m_finalize_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer, *args, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdraw_wrapper\u001b[39m(artist, renderer, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     result = \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m renderer._rasterizing:\n\u001b[32m     96\u001b[39m         renderer.stop_rasterizing()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/artist.py:71\u001b[39m, in \u001b[36mallow_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     69\u001b[39m         renderer.start_filter()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/figure.py:3257\u001b[39m, in \u001b[36mFigure.draw\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m   3254\u001b[39m             \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[32m   3256\u001b[39m     \u001b[38;5;28mself\u001b[39m.patch.draw(renderer)\n\u001b[32m-> \u001b[39m\u001b[32m3257\u001b[39m     \u001b[43mmimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3260\u001b[39m     renderer.close_group(\u001b[33m'\u001b[39m\u001b[33mfigure\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   3261\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/image.py:134\u001b[39m, in \u001b[36m_draw_list_compositing_images\u001b[39m\u001b[34m(renderer, parent, artists, suppress_composite)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m         \u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[32m    137\u001b[39m     image_group = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/artist.py:71\u001b[39m, in \u001b[36mallow_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     69\u001b[39m         renderer.start_filter()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/axes/_base.py:3181\u001b[39m, in \u001b[36m_AxesBase.draw\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m   3178\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m artists_rasterized:\n\u001b[32m   3179\u001b[39m     _draw_rasterized(\u001b[38;5;28mself\u001b[39m.get_figure(root=\u001b[38;5;28;01mTrue\u001b[39;00m), artists_rasterized, renderer)\n\u001b[32m-> \u001b[39m\u001b[32m3181\u001b[39m \u001b[43mmimage\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3182\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3184\u001b[39m renderer.close_group(\u001b[33m'\u001b[39m\u001b[33maxes\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   3185\u001b[39m \u001b[38;5;28mself\u001b[39m.stale = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/image.py:134\u001b[39m, in \u001b[36m_draw_list_compositing_images\u001b[39m\u001b[34m(renderer, parent, artists, suppress_composite)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m         \u001b[43ma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[32m    137\u001b[39m     image_group = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/artist.py:71\u001b[39m, in \u001b[36mallow_rasterization.<locals>.draw_wrapper\u001b[39m\u001b[34m(artist, renderer)\u001b[39m\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     69\u001b[39m         renderer.start_filter()\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m artist.get_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/axis.py:1415\u001b[39m, in \u001b[36mAxis.draw\u001b[39m\u001b[34m(self, renderer)\u001b[39m\n\u001b[32m   1412\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1413\u001b[39m renderer.open_group(\u001b[34m__name__\u001b[39m, gid=\u001b[38;5;28mself\u001b[39m.get_gid())\n\u001b[32m-> \u001b[39m\u001b[32m1415\u001b[39m ticks_to_draw = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_ticks\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1416\u001b[39m tlb1, tlb2 = \u001b[38;5;28mself\u001b[39m._get_ticklabel_bboxes(ticks_to_draw, renderer)\n\u001b[32m   1418\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks_to_draw:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/axis.py:1294\u001b[39m, in \u001b[36mAxis._update_ticks\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1292\u001b[39m major_locs = \u001b[38;5;28mself\u001b[39m.get_majorticklocs()\n\u001b[32m   1293\u001b[39m major_labels = \u001b[38;5;28mself\u001b[39m.major.formatter.format_ticks(major_locs)\n\u001b[32m-> \u001b[39m\u001b[32m1294\u001b[39m major_ticks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_major_ticks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmajor_locs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1295\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tick, loc, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(major_ticks, major_locs, major_labels):\n\u001b[32m   1296\u001b[39m     tick.update_position(loc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/axis.py:1677\u001b[39m, in \u001b[36mAxis.get_major_ticks\u001b[39m\u001b[34m(self, numticks)\u001b[39m\n\u001b[32m   1675\u001b[39m     tick = \u001b[38;5;28mself\u001b[39m._get_tick(major=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1676\u001b[39m     \u001b[38;5;28mself\u001b[39m.majorTicks.append(tick)\n\u001b[32m-> \u001b[39m\u001b[32m1677\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_copy_tick_props\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmajorTicks\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtick\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1679\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.majorTicks[:numticks]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/axis.py:1623\u001b[39m, in \u001b[36mAxis._copy_tick_props\u001b[39m\u001b[34m(self, src, dest)\u001b[39m\n\u001b[32m   1621\u001b[39m dest.label1.update_from(src.label1)\n\u001b[32m   1622\u001b[39m dest.label2.update_from(src.label2)\n\u001b[32m-> \u001b[39m\u001b[32m1623\u001b[39m \u001b[43mdest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick1line\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate_from\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick1line\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1624\u001b[39m dest.tick2line.update_from(src.tick2line)\n\u001b[32m   1625\u001b[39m dest.gridline.update_from(src.gridline)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/lines.py:1358\u001b[39m, in \u001b[36mLine2D.update_from\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m   1355\u001b[39m \u001b[38;5;28mself\u001b[39m._solidjoinstyle = other._solidjoinstyle\n\u001b[32m   1357\u001b[39m \u001b[38;5;28mself\u001b[39m._linestyle = other._linestyle\n\u001b[32m-> \u001b[39m\u001b[32m1358\u001b[39m \u001b[38;5;28mself\u001b[39m._marker = \u001b[43mMarkerStyle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarker\u001b[49m\u001b[43m=\u001b[49m\u001b[43mother\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_marker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1359\u001b[39m \u001b[38;5;28mself\u001b[39m._drawstyle = other._drawstyle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/markers.py:248\u001b[39m, in \u001b[36mMarkerStyle.__init__\u001b[39m\u001b[34m(self, marker, fillstyle, transform, capstyle, joinstyle)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;28mself\u001b[39m._user_joinstyle = JoinStyle(joinstyle) \u001b[38;5;28;01mif\u001b[39;00m joinstyle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[38;5;28mself\u001b[39m._set_fillstyle(fillstyle)\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_marker\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarker\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/markers.py:323\u001b[39m, in \u001b[36mMarkerStyle._set_marker\u001b[39m\u001b[34m(self, marker)\u001b[39m\n\u001b[32m    321\u001b[39m     \u001b[38;5;28mself\u001b[39m._marker_function = \u001b[38;5;28mself\u001b[39m._set_tuple_marker\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(marker, MarkerStyle):\n\u001b[32m--> \u001b[39m\u001b[32m323\u001b[39m     \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m = \u001b[43mcopy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarker\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__dict__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/copy.py:131\u001b[39m, in \u001b[36mdeepcopy\u001b[39m\u001b[34m(x, memo, _nil)\u001b[39m\n\u001b[32m    129\u001b[39m copier = _deepcopy_dispatch.get(\u001b[38;5;28mcls\u001b[39m)\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     y = \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/copy.py:202\u001b[39m, in \u001b[36m_deepcopy_dict\u001b[39m\u001b[34m(x, memo, deepcopy)\u001b[39m\n\u001b[32m    200\u001b[39m memo[\u001b[38;5;28mid\u001b[39m(x)] = y\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x.items():\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     y[deepcopy(key, memo)] = \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/copy.py:138\u001b[39m, in \u001b[36mdeepcopy\u001b[39m\u001b[34m(x, memo, _nil)\u001b[39m\n\u001b[32m    136\u001b[39m copier = \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33m__deepcopy__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     y = \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    140\u001b[39m     reductor = dispatch_table.get(\u001b[38;5;28mcls\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/path.py:285\u001b[39m, in \u001b[36mPath.__deepcopy__\u001b[39m\u001b[34m(self, memo)\u001b[39m\n\u001b[32m    280\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    281\u001b[39m \u001b[33;03mReturn a deepcopy of the `Path`.  The `Path` will not be\u001b[39;00m\n\u001b[32m    282\u001b[39m \u001b[33;03mreadonly, even if the source `Path` is.\u001b[39;00m\n\u001b[32m    283\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    284\u001b[39m \u001b[38;5;66;03m# Deepcopying arrays (vertices, codes) strips the writeable=False flag.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m p = \u001b[43mcopy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    286\u001b[39m p._readonly = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/copy.py:157\u001b[39m, in \u001b[36mdeepcopy\u001b[39m\u001b[34m(x, memo, _nil)\u001b[39m\n\u001b[32m    155\u001b[39m                 y = x\n\u001b[32m    156\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m                 y = \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/copy.py:234\u001b[39m, in \u001b[36m_reconstruct\u001b[39m\u001b[34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m args:\n\u001b[32m    233\u001b[39m     args = (deepcopy(arg, memo) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m y = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[32m    236\u001b[39m     memo[\u001b[38;5;28mid\u001b[39m(x)] = y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/copy.py:233\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    231\u001b[39m deep = memo \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m args:\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m     args = (\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n\u001b[32m    234\u001b[39m y = func(*args)\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/copy.py:138\u001b[39m, in \u001b[36mdeepcopy\u001b[39m\u001b[34m(x, memo, _nil)\u001b[39m\n\u001b[32m    136\u001b[39m copier = \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33m__deepcopy__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     y = \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    140\u001b[39m     reductor = dispatch_table.get(\u001b[38;5;28mcls\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/path.py:285\u001b[39m, in \u001b[36mPath.__deepcopy__\u001b[39m\u001b[34m(self, memo)\u001b[39m\n\u001b[32m    280\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    281\u001b[39m \u001b[33;03mReturn a deepcopy of the `Path`.  The `Path` will not be\u001b[39;00m\n\u001b[32m    282\u001b[39m \u001b[33;03mreadonly, even if the source `Path` is.\u001b[39;00m\n\u001b[32m    283\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    284\u001b[39m \u001b[38;5;66;03m# Deepcopying arrays (vertices, codes) strips the writeable=False flag.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m p = \u001b[43mcopy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    286\u001b[39m p._readonly = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/copy.py:157\u001b[39m, in \u001b[36mdeepcopy\u001b[39m\u001b[34m(x, memo, _nil)\u001b[39m\n\u001b[32m    155\u001b[39m                 y = x\n\u001b[32m    156\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m                 y = \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/copy.py:234\u001b[39m, in \u001b[36m_reconstruct\u001b[39m\u001b[34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m args:\n\u001b[32m    233\u001b[39m     args = (deepcopy(arg, memo) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m y = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[32m    236\u001b[39m     memo[\u001b[38;5;28mid\u001b[39m(x)] = y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/copy.py:233\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    231\u001b[39m deep = memo \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m args:\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m     args = (\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n\u001b[32m    234\u001b[39m y = func(*args)\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep:\n",
      "    \u001b[31m[... skipping similar frames: Path.__deepcopy__ at line 285 (589 times), deepcopy at line 138 (589 times), <genexpr> at line 233 (588 times), _reconstruct at line 234 (588 times), deepcopy at line 157 (588 times)]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/copy.py:157\u001b[39m, in \u001b[36mdeepcopy\u001b[39m\u001b[34m(x, memo, _nil)\u001b[39m\n\u001b[32m    155\u001b[39m                 y = x\n\u001b[32m    156\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m                 y = \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/copy.py:234\u001b[39m, in \u001b[36m_reconstruct\u001b[39m\u001b[34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m args:\n\u001b[32m    233\u001b[39m     args = (deepcopy(arg, memo) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m y = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[32m    236\u001b[39m     memo[\u001b[38;5;28mid\u001b[39m(x)] = y\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/copy.py:233\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    231\u001b[39m deep = memo \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m args:\n\u001b[32m--> \u001b[39m\u001b[32m233\u001b[39m     args = (\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n\u001b[32m    234\u001b[39m y = func(*args)\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m deep:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/copy.py:138\u001b[39m, in \u001b[36mdeepcopy\u001b[39m\u001b[34m(x, memo, _nil)\u001b[39m\n\u001b[32m    136\u001b[39m copier = \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33m__deepcopy__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     y = \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    140\u001b[39m     reductor = dispatch_table.get(\u001b[38;5;28mcls\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/genai/lib/python3.14/site-packages/matplotlib/path.py:285\u001b[39m, in \u001b[36mPath.__deepcopy__\u001b[39m\u001b[34m(self, memo)\u001b[39m\n\u001b[32m    280\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    281\u001b[39m \u001b[33;03mReturn a deepcopy of the `Path`.  The `Path` will not be\u001b[39;00m\n\u001b[32m    282\u001b[39m \u001b[33;03mreadonly, even if the source `Path` is.\u001b[39;00m\n\u001b[32m    283\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    284\u001b[39m \u001b[38;5;66;03m# Deepcopying arrays (vertices, codes) strips the writeable=False flag.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m p = \u001b[43mcopy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    286\u001b[39m p._readonly = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "\u001b[31mRecursionError\u001b[39m: maximum recursion depth exceeded"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = []\n",
    "psnr = PeakSignalNoiseRatio(data_range=1.0).to(accelerator.device)\n",
    "ssim = StructuralSimilarityIndexMeasure(data_range=1.0).to(accelerator.device)\n",
    "\n",
    "for batch in test_loader:\n",
    "    with torch.no_grad():\n",
    "        prompt_embeds_eval = compute_embeddings_sd1x5(\n",
    "            batch=batch,\n",
    "            proportion_empty_prompts=0.0,  # Use 0.0 for evaluation when skipping CFG\n",
    "            text_encoders=text_encoders,\n",
    "            tokenizers=tokenizers,\n",
    "            accelerator=accelerator,\n",
    "        )[\"prompt_embeds\"]\n",
    "    image_batch_np, postprocessed = generate_mri_slices_partial_latent_align_dc(\n",
    "        batch=batch,\n",
    "        adapter=adapter,\n",
    "        mri_projector=mri_projector,\n",
    "        inverse_latent_projector=inverse_latent_projector,\n",
    "        unet=unet,\n",
    "        vae=vae,\n",
    "        noise_scheduler=noise_scheduler,\n",
    "        prompt_embeds=prompt_embeds_eval,\n",
    "        start_step=t2i_config.partial_start_step,  # Start from t=250\n",
    "        num_inference_steps=500,  # Scheduler will slice this\n",
    "        weight_dtype=weight_dtype,\n",
    "        accelerator=accelerator,\n",
    "        use_data_consistency=True,\n",
    "        dc_reduction_factor=1.7,\n",
    "        taper=0.12,\n",
    "        apply_final_pixel_dc=False,\n",
    "    )\n",
    "    channels = image_batch_np.shape[3]\n",
    "    if batch[\"hr\"].ndim == 3:\n",
    "        gt = (\n",
    "            batch[\"hr\"]\n",
    "            .unsqueeze(1)\n",
    "            .expand((t2i_config.test_batch_size, channels, 512, 512))\n",
    "            .to(accelerator.device)\n",
    "        )\n",
    "    else:\n",
    "        gt = (\n",
    "            batch[\"hr\"]\n",
    "            .expand((t2i_config.test_batch_size, 512, 512, channels))\n",
    "            .permute(0, 3, 1, 2)\n",
    "            .to(accelerator.device),\n",
    "        )\n",
    "    metrics_batch = MRIEvaluator.eval_all_metrics(\n",
    "        ground_truth=gt,\n",
    "        generated=torch.from_numpy(image_batch_np)\n",
    "        .permute(0, 3, 1, 2)\n",
    "        .to(accelerator.device),\n",
    "        psnr=psnr,\n",
    "        ssim=ssim,\n",
    "    )  # returns hfen, nmse, psnr, ssim\n",
    "    metrics.append(metrics_batch)\n",
    "\n",
    "metrics_np = np.array(metrics)  # shape: (num_batches, 4)\n",
    "avg_metrics = metrics_np.mean(axis=0)\n",
    "run.summary[\"hfen\"] = float(avg_metrics[0])\n",
    "run.summary[\"nmse\"] = float(avg_metrics[1])\n",
    "run.summary[\"psnr\"] = float(avg_metrics[2])\n",
    "run.summary[\"ssim\"] = float(avg_metrics[3])\n",
    "\n",
    "\n",
    "plot_generated_and_ground_truth(\n",
    "    generated_slices_np=image_batch_np, batch=batch, num_images_to_show=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99db317",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
